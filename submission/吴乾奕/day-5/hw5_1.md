# 答题卡

## 1 并行策略与张量 shape

### 1.1

#### 1.1.1
每个rank上权重矩阵的shape：d * 4d/P = 1024 * 1024

#### 1.1.2 
X不会做切分，X的shape：8 * 128 * 1024

#### 1.1.3 
按列进行拼接，完整输出Y的shape：8 * 128 * 4096，最终完整的输出是将P=4个输出按最后一个维度拼接起来。


### 1.2 行并行

#### 1.2.1 
每个rank上权重矩阵的shape：4d/P * d = 1024 * 1024

#### 1.2.2 
X的shape：8 * 128 * 1024

#### 1.2.3 
行并行中，每个rank的输出shape是完整的：8 * 128 * 1024，通过All-Reduce操作对rank的输出相加得到完整的Z。



## 2 通信分析

### 2.1

#### 2.1.1 

需要通讯，All-Gather在最后一个维度拼接输出，通讯量 = (P-1)*8*128*1024 = 3.14MB

####2.1.2 

需要通讯，W1按列划分，每个rank只包含部分列，因此每个rank只能计算X的部分题目，需要通过All-Reduce合并rank的结果才能得到完整的梯度

### 2.2

#### 2.2.1 
不需要通讯，Linear2的输入已经分片，每个rank只要接收对应的输入子张量Yi，可以使用W2完成计算，最终输出维度是完整的，不需要拼接

#### 2.2.2 
需要通讯，W2按行划分，各个rank拥有W2的不同列，每个rank只能计算出部分梯度，需要通过All-Gather操作

## 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？
(1) 如果两层都使用 Row Parallel，虽然每层的前向传播无需通信，但在层与层之间，由于输出和下一层输入的划分方式不一致，需要进行一次 All-to-All 通信来重排中间激活值，通信代价较高，容易成为性能瓶颈。
(2) 如果两层都使用 Column Parallel，则每层之间需要 All-Gather 来拼接完整输入用于下一层计算，同时反向传播中也需要 All-Reduce 合并梯度，导致通信频繁、效率低。
